{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laravel RAG LLM - Complete Pipeline\n",
    "\n",
    "Notebook ini berisi complete pipeline untuk Laravel RAG (Retrieval Augmented Generation) LLM menggunakan GPT-2.\n",
    "\n",
    "## Struktur:\n",
    "1. **Setup & Installation** - Install dependencies dan import libraries\n",
    "2. **Configuration** - Load configuration\n",
    "3. **Data Exploration** - Explore dataset Laravel\n",
    "4. **Data Processing** - Process data untuk training\n",
    "5. **Model Loading** - Load GPT-2 model\n",
    "6. **Model Training** - Fine-tune model (Optional)\n",
    "7. **RAG Setup** - Setup retrieval system\n",
    "8. **Inference** - Test RAG system\n",
    "9. **Interactive Demo** - Try your own queries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n**‚ö° QUICK START**: Untuk langsung testing RAG system, run cells berikut secara berurutan:\n1. Cell #2 (Install dependencies)\n2. Cell #3 (Setup & imports)\n3. Cell #4 (Load configuration)\n4. Cell #7 (Load model)\n5. Cell #9 (Setup RAG)\n6. Cell #11 atau #12 (Interactive demo)\n\n**üìö FULL TUTORIAL**: Ikuti semua cells step-by-step untuk memahami seluruh pipeline.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q transformers torch datasets pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import libraries and setup path\nimport sys\nimport os\nimport json\nimport torch\nfrom pathlib import Path\n\n# Get notebook directory and project root\nnotebook_dir = os.getcwd()\nproject_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n\n# Add src to path if not already there\nsrc_path = os.path.join(project_root, 'src')\nif src_path not in sys.path:\n    sys.path.insert(0, src_path)\n\nprint(f\"üìÅ Project root: {project_root}\")\nprint(f\"üìÅ Notebook directory: {notebook_dir}\")\nprint(f\"üìÅ Source path: {src_path}\")\n\n# Check device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\nüñ•Ô∏è  Using device: {device}\")\nprint(f\"üêç Python version: {sys.version}\")\nprint(f\"üî• PyTorch version: {torch.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load configuration\nfrom config_loader import ConfigLoader\n\n# Use absolute path\nconfig_path = os.path.join(project_root, 'configs', 'config.json')\nconfig = ConfigLoader(config_path=config_path)\n\nprint(\"üìã Configuration loaded:\")\nprint(f\"  Config file: {config_path}\")\nprint(f\"  Model: {config.get('model.name')}\")\nprint(f\"  Training epochs: {config.get('training.num_train_epochs')}\")\nprint(f\"  Max sequence length: {config.get('training.max_seq_length')}\")\nprint(f\"  Batch size: {config.get('training.per_device_train_batch_size')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load dan explore raw dataset\nimport pandas as pd\n\n# Load raw QA dataset using absolute path\nraw_data_path = os.path.join(project_root, 'data', 'raw', 'laravel_qa_dataset.json')\nwith open(raw_data_path, 'r', encoding='utf-8') as f:\n    raw_data = json.load(f)\n\n# Convert to DataFrame untuk easy viewing\ndf = pd.DataFrame(raw_data)\n\nprint(f\"üìä Dataset Statistics:\")\nprint(f\"  Dataset file: {raw_data_path}\")\nprint(f\"  Total QA pairs: {len(df)}\")\nprint(f\"  Categories: {df['category'].unique().tolist()}\")\nprint(f\"  Difficulty levels: {df['difficulty'].unique().tolist()}\")\nprint(f\"\\nüìà Category distribution:\")\nprint(df['category'].value_counts())\n\n# Show sample\nprint(\"\\nüìù Sample QA pair:\")\nsample = raw_data[0]\nprint(f\"Q: {sample['question']}\")\nprint(f\"A: {sample['answer'][:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process data untuk training\nfrom data_processing import DataProcessor\n\n# Use absolute paths\nraw_data_path = os.path.join(project_root, 'data', 'raw', 'laravel_qa_dataset.json')\nprocessed_data_path = os.path.join(project_root, 'data', 'processed', 'training_data.json')\n\nprocessor = DataProcessor(\n    raw_data_path=raw_data_path,\n    processed_data_path=processed_data_path\n)\n\n# Process and save\nprocessor.process_and_save()\n\n# Load processed data\nprocessed_data = processor.load_processed_data()\n\nprint(f\"\\n‚úÖ Processed {len(processed_data)} training samples\")\nprint(\"\\nüìù Sample training format:\")\nprint(f\"Prompt: {processed_data[0]['prompt']}\")\nprint(f\"Completion: {processed_data[0]['completion'][:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 model\n",
    "from model_utils import ModelManager\n",
    "\n",
    "# Initialize model manager\n",
    "model_manager = ModelManager(\n",
    "    model_name=config.get('model.name', 'gpt2'),\n",
    "    model_path=config.get('model.model_path'),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load model (will try fine-tuned first, fallback to base gpt2)\n",
    "model_manager.load_model(from_pretrained=True)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training (Optional)\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Training membutuhkan waktu dan resource. Skip section ini jika:\n",
    "- Sudah punya model yang di-fine-tune\n",
    "- Mau testing dulu dengan base model\n",
    "- Resource terbatas\n",
    "\n",
    "Uncomment cell di bawah untuk training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training (OPTIONAL - Uncomment untuk train)\n",
    "# from transformers import GPT2Tokenizer\n",
    "# \n",
    "# print(\"üöÄ Starting training...\")\n",
    "# print(\"‚è∞ This may take 10-30 minutes depending on your hardware\\n\")\n",
    "# \n",
    "# # Create dataset\n",
    "# train_dataset = processor.create_dataset_for_training(\n",
    "#     tokenizer=model_manager.tokenizer,\n",
    "#     max_length=config.get('training.max_seq_length', 256)\n",
    "# )\n",
    "# \n",
    "# print(f\"üìä Training dataset size: {len(train_dataset)}\")\n",
    "# \n",
    "# # Train model\n",
    "# model_manager.train_model(\n",
    "#     train_dataset=train_dataset,\n",
    "#     output_dir=config.get('training.output_dir'),\n",
    "#     num_train_epochs=config.get('training.num_train_epochs'),\n",
    "#     per_device_train_batch_size=config.get('training.per_device_train_batch_size'),\n",
    "#     gradient_accumulation_steps=config.get('training.gradient_accumulation_steps'),\n",
    "#     learning_rate=config.get('training.learning_rate'),\n",
    "#     warmup_steps=config.get('training.warmup_steps'),\n",
    "#     save_steps=config.get('training.save_steps'),\n",
    "#     logging_steps=config.get('training.logging_steps'),\n",
    "#     save_total_limit=config.get('training.save_total_limit')\n",
    "# )\n",
    "# \n",
    "# print(\"\\n‚úÖ Training complete!\")\n",
    "# print(\"üì¶ Model saved to:\", config.get('training.output_dir'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup RAG retrieval system\nfrom retrieval import RAGRetriever, KnowledgeBase\nfrom model_utils import RAGGenerator\n\n# Use absolute path for knowledge base\nkb_path = os.path.join(project_root, 'data', 'knowledge_base', 'local_db.json')\n\n# Initialize retriever\nretriever = RAGRetriever(\n    kb_path=kb_path,\n    use_web_fallback=config.get('retrieval.use_web_fallback', False)\n)\n\nprint(\"üìö Knowledge base loaded\")\nprint(f\"  KB path: {kb_path}\")\nretriever.kb.show_all()\n\n# Initialize RAG generator\nrag_generator = RAGGenerator(\n    model_manager=model_manager,\n    retriever=retriever\n)\n\nprint(\"\\n‚úÖ RAG system ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG system dengan sample queries\n",
    "test_queries = [\n",
    "    \"Bagaimana cara install Laravel?\",\n",
    "    \"Apa itu Eloquent ORM?\",\n",
    "    \"Bagaimana cara membuat controller?\",\n",
    "    \"Bagaimana cara membuat migration?\",\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing RAG System\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"‚ùì Query: {query}\")\n",
    "    \n",
    "    # Generate response\n",
    "    result = rag_generator.generate_with_context(\n",
    "        query=query,\n",
    "        max_new_tokens=config.get('generation.max_new_tokens', 200),\n",
    "        temperature=config.get('model.temperature', 0.7)\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Confidence: {result['confidence']:.2f} | Method: {result['method']}\")\n",
    "    print(f\"üí° Answer: {result['answer'][:300]}...\\n\")\n",
    "    print(\"-\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interactive Demo\n",
    "\n",
    "Try your own queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query function\n",
    "def ask_laravel_question(query: str, show_context: bool = False):\n",
    "    \"\"\"\n",
    "    Ask a Laravel-related question\n",
    "    \n",
    "    Args:\n",
    "        query: Your question\n",
    "        show_context: Show retrieved context\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚ùì Your Question: {query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Generate response\n",
    "    result = rag_generator.generate_with_context(\n",
    "        query=query,\n",
    "        max_new_tokens=config.get('generation.max_new_tokens', 200),\n",
    "        temperature=config.get('model.temperature', 0.7)\n",
    "    )\n",
    "    \n",
    "    # Show results\n",
    "    print(f\"üìä Confidence: {result['confidence']:.2f}\")\n",
    "    print(f\"üîç Method: {result['method']}\")\n",
    "    \n",
    "    if show_context:\n",
    "        print(f\"\\nüìö Context Retrieved:\")\n",
    "        print(f\"{result['context'][:300]}...\\n\")\n",
    "    \n",
    "    print(f\"\\nüí° Answer:\")\n",
    "    print(f\"{result['answer']}\")\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# ask_laravel_question(\"Bagaimana cara membuat API di Laravel?\")\n",
    "# ask_laravel_question(\"Apa itu middleware?\", show_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own questions here!\n",
    "ask_laravel_question(\"Bagaimana cara membuat authentication di Laravel?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask another question\n",
    "ask_laravel_question(\"Bagaimana cara validasi form?\", show_context=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced: Add New Knowledge\n",
    "\n",
    "Anda bisa menambahkan knowledge baru ke knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new knowledge entry\n",
    "def add_knowledge(query: str, answer: str):\n",
    "    \"\"\"Add new entry to knowledge base\"\"\"\n",
    "    retriever.kb.add_entry(query, answer)\n",
    "    print(f\"‚úÖ Added new knowledge entry\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer[:100]}...\")\n",
    "\n",
    "# Example:\n",
    "# add_knowledge(\n",
    "#     \"cara deploy laravel\",\n",
    "#     \"Untuk deploy Laravel: 1) Setup server dengan PHP 8.1+, 2) Clone repository, 3) Run composer install, 4) Setup .env file, 5) Generate key: php artisan key:generate, 6) Run migrations, 7) Configure web server (Nginx/Apache)\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ What we built:\n",
    "1. **Data Pipeline**: Raw data ‚Üí Processed training data\n",
    "2. **RAG System**: Knowledge base + Retrieval + GPT-2 Generation\n",
    "3. **Fine-tuning**: Optional model training on Laravel-specific data\n",
    "4. **Interactive Interface**: Ask Laravel questions and get AI-powered answers\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Expand Dataset**: Add more Laravel QA pairs ke `data/raw/`\n",
    "2. **Fine-tune**: Train model dengan dataset yang lebih besar\n",
    "3. **Improve Retrieval**: Implement semantic search dengan embeddings\n",
    "4. **Add Web Interface**: Build Flask/FastAPI backend + React frontend\n",
    "5. **Deploy**: Deploy model ke production\n",
    "\n",
    "### üìö Resources:\n",
    "- [Laravel Documentation](https://laravel.com/docs)\n",
    "- [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "- [RAG Papers](https://arxiv.org/abs/2005.11401)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}