{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ Laravel RAG LLM - Google Colab Version\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ubaidillahfaris/LLM/blob/main/notebooks/Colab_Quick_Start.ipynb)\n",
    "\n",
    "Notebook ini di-optimize untuk **Google Colab** dengan auto-detection path.\n",
    "\n",
    "**Just run all cells! üéâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-1"
   },
   "source": [
    "## Step 1: Clone Repository (Skip jika sudah ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if already cloned\n",
    "if not os.path.exists('/content/LLM'):\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone https://github.com/ubaidillahfaris/LLM.git /content/LLM\n",
    "    print(\"‚úÖ Repository cloned!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd /content/LLM\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "‚è∞ **Wait time**: 2-3 minutes di Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pip-install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets pandas numpy tqdm\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-path"
   },
   "source": [
    "## Step 3: Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Auto-detect project root (works in Colab, local, and other environments)\n",
    "if os.path.exists('/content/LLM'):\n",
    "    # Google Colab\n",
    "    project_root = '/content/LLM'\n",
    "elif os.path.exists('/home/user/LLM'):\n",
    "    # Local environment\n",
    "    project_root = '/home/user/LLM'\n",
    "else:\n",
    "    # Try to find based on current directory\n",
    "    current = os.getcwd()\n",
    "    if 'LLM' in current:\n",
    "        # Navigate up until we find LLM root\n",
    "        while os.path.basename(current) != 'LLM' and current != '/':\n",
    "            current = os.path.dirname(current)\n",
    "        project_root = current\n",
    "    else:\n",
    "        project_root = os.getcwd()\n",
    "\n",
    "# Add src to path\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(\"üìÅ Environment Detection:\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   Source path: {src_path}\")\n",
    "print(f\"   Current dir: {os.getcwd()}\")\n",
    "\n",
    "# Verify structure\n",
    "required_dirs = ['src', 'data', 'configs']\n",
    "all_exist = True\n",
    "for d in required_dirs:\n",
    "    path = os.path.join(project_root, d)\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"   {status} {d}/\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"\\n‚ö†Ô∏è  Some directories are missing! Did you clone the repo?\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Project structure validated!\")\n",
    "\n",
    "# Import modules\n",
    "try:\n",
    "    from config_loader import ConfigLoader\n",
    "    from retrieval import RAGRetriever\n",
    "    from model_utils import ModelManager, RAGGenerator\n",
    "    print(\"\\n‚úÖ All modules imported successfully!\")\n",
    "    \n",
    "    # Check device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device == \"cuda\":\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"üöÄ GPU detected: {gpu_name}\")\n",
    "    else:\n",
    "        print(f\"üíª Running on CPU\")\n",
    "        \nexcept ImportError as e:\n",
    "    print(f\"\\n‚ùå Import error: {e}\")\n",
    "    print(\"\\nüîß Try running Step 2 again or restart runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load-config"
   },
   "source": [
    "## Step 4: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Load config using detected project root\n",
    "config_path = os.path.join(project_root, 'configs', 'config.json')\n",
    "\n",
    "print(f\"üìã Loading config from: {config_path}\")\n",
    "config = ConfigLoader(config_path=config_path)\n",
    "\n",
    "print(\"\\n‚úÖ Configuration loaded!\")\n",
    "print(f\"   Model: {config.get('model.name')}\")\n",
    "print(f\"   Temperature: {config.get('model.temperature')}\")\n",
    "print(f\"   Max tokens: {config.get('generation.max_new_tokens')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load-model"
   },
   "source": [
    "## Step 5: Load GPT-2 Model\n",
    "\n",
    "‚è∞ **Wait time**: 1-2 minutes (first time download ~500MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model"
   },
   "outputs": [],
   "source": [
    "# Initialize model manager\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"üì¶ Initializing model manager...\")\n",
    "model_manager = ModelManager(\n",
    "    model_name=\"gpt2\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\nüì• Loading GPT-2 model...\")\n",
    "print(\"   (This may take 1-2 minutes on first run)\")\n",
    "model_manager.load_model(from_pretrained=True)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded and ready!\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Model: {model_manager.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-rag"
   },
   "source": [
    "## Step 6: Setup RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rag-setup"
   },
   "outputs": [],
   "source": [
    "# Setup knowledge base path\n",
    "kb_path = os.path.join(project_root, 'data', 'knowledge_base', 'local_db.json')\n",
    "\n",
    "print(f\"üìö Loading knowledge base from:\")\n",
    "print(f\"   {kb_path}\")\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = RAGRetriever(kb_path=kb_path)\n",
    "\n",
    "print(\"\\nüìñ Knowledge Base Contents:\")\n",
    "retriever.kb.show_all()\n",
    "\n",
    "# Initialize RAG generator\n",
    "rag_generator = RAGGenerator(model_manager, retriever)\n",
    "\n",
    "print(\"\\n‚úÖ RAG system ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## Step 7: Test RAG System üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-query"
   },
   "outputs": [],
   "source": [
    "# Test dengan sample query\n",
    "test_query = \"Bagaimana cara install Laravel?\"\n",
    "\n",
    "print(f\"‚ùì Test Question: {test_query}\\n\")\n",
    "print(\"ü§ñ Generating answer...\\n\")\n",
    "\n",
    "result = rag_generator.generate_with_context(\n",
    "    query=test_query,\n",
    "    max_new_tokens=config.get('generation.max_new_tokens', 200),\n",
    "    temperature=config.get('model.temperature', 0.7)\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"üîç Retrieval Method: {result['method']}\")\n",
    "print(f\"\\nüí° Answer:\\n{result['answer']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive"
   },
   "source": [
    "## Step 8: Interactive Q&A üéØ\n",
    "\n",
    "Sekarang lu bisa tanya apapun tentang Laravel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ask-function"
   },
   "outputs": [],
   "source": [
    "def ask(question: str, show_context: bool = False):\n",
    "    \"\"\"\n",
    "    Ask a Laravel question\n",
    "    \n",
    "    Args:\n",
    "        question: Your Laravel-related question\n",
    "        show_context: Show retrieved context (default: False)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"‚ùì {question}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "    \n",
    "    result = rag_generator.generate_with_context(\n",
    "        query=question,\n",
    "        max_new_tokens=config.get('generation.max_new_tokens', 200),\n",
    "        temperature=config.get('model.temperature', 0.7)\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Confidence: {result['confidence']:.2%} | Method: {result['method']}\")\n",
    "    \n",
    "    if show_context and result['context']:\n",
    "        print(f\"\\nüìö Retrieved Context:\")\n",
    "        print(f\"{result['context'][:200]}...\\n\")\n",
    "    \n",
    "    print(f\"\\nüí° Answer:\\n{result['answer']}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Function 'ask()' ready!\")\n",
    "print(\"\\nüìù Usage: ask('Your question here')\")\n",
    "print(\"   Example: ask('Apa itu Eloquent ORM?')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-1"
   },
   "outputs": [],
   "source": [
    "# Try different questions!\n",
    "ask(\"Apa itu Eloquent ORM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-2"
   },
   "outputs": [],
   "source": [
    "ask(\"Bagaimana cara membuat controller?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-3"
   },
   "outputs": [],
   "source": [
    "ask(\"Bagaimana cara membuat middleware?\", show_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom-question"
   },
   "outputs": [],
   "source": [
    "# Your custom question here!\n",
    "ask(\"YOUR QUESTION HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "explore-data"
   },
   "source": [
    "## Bonus: Explore Dataset üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-dataset"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw dataset\n",
    "dataset_path = os.path.join(project_root, 'data', 'raw', 'laravel_qa_dataset.json')\n",
    "with open(dataset_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(f\"   Total QA pairs: {len(df)}\")\n",
    "print(f\"   Categories: {df['category'].nunique()}\")\n",
    "print(f\"\\nüìà Distribution by category:\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "print(f\"\\nüìà Distribution by difficulty:\")\n",
    "print(df['difficulty'].value_counts())\n",
    "\n",
    "# Show dataframe\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "df[['question', 'category', 'difficulty']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "success"
   },
   "source": [
    "## üéä Success!\n",
    "\n",
    "RAG system sekarang running di Google Colab!\n",
    "\n",
    "### üöÄ What's Next?\n",
    "\n",
    "1. **Ask more questions** - Edit cells di atas dengan pertanyaan lu\n",
    "2. **Add knowledge** - Edit `data/knowledge_base/local_db.json`\n",
    "3. **Expand dataset** - Tambah QA ke `data/raw/laravel_qa_dataset.json`\n",
    "4. **Fine-tune model** - Buka `Laravel_RAG_LLM_Complete.ipynb` untuk training\n",
    "\n",
    "### üìö Resources\n",
    "\n",
    "- [GitHub Repo](https://github.com/ubaidillahfaris/LLM)\n",
    "- [Laravel Docs](https://laravel.com/docs)\n",
    "- [Transformers Docs](https://huggingface.co/docs/transformers)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
